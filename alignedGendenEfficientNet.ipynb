{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alignedGendenEfficientNet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi2bD-3JgRSj",
        "outputId": "841c7ffa-ea6b-4f37-a068-574f918bec6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHHU8MhgZaT",
        "outputId": "b990fa48-5a2b-4fd7-8e82-142bc881bec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "%pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/My Drive/Adience/alignedGender.rar\", outdir=\"/content\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting /content/drive/My Drive/Adience/alignedGender.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/drive/My Drive/Adience/alignedGender.rar\"\n",
            "patool:     with cwd='/content'\n",
            "patool: ... /content/drive/My Drive/Adience/alignedGender.rar extracted to `/content'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-4IismlglgK",
        "outputId": "cedd6875-0aa1-4598-b7ed-f76882c25bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import  tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, PReLU, ReLU, Input, GlobalAveragePooling2D\n",
        "from keras import optimizers, regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "np.random.seed(48)\n",
        "from keras.applications import vgg19\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "# input_shape = (224, 224, 3)\n",
        "# vgg = vgg19.VGG19(include_top=False ,weights='imagenet', \n",
        "#                                      input_shape=input_shape)   \n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgVA7TDSFVbX"
      },
      "source": [
        "seed = 1234\n",
        "rn.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg_7vrHamakt"
      },
      "source": [
        "### Group Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffFhddktmYFj",
        "outputId": "388294f1-6c28-4cb3-a9c4-27b521a505ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "\n",
        "class GroupNormalization(Layer):\n",
        "    \"\"\"Group normalization layer\n",
        "    Group Normalization divides the channels into groups and computes within each group\n",
        "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
        "    and its accuracy is stable in a wide range of batch sizes\n",
        "    # Arguments\n",
        "        groups: Integer, the number of groups for Group Normalization.\n",
        "        axis: Integer, the axis that should be normalized\n",
        "            (typically the features axis).\n",
        "            For instance, after a `Conv2D` layer with\n",
        "            `data_format=\"channels_first\"`,\n",
        "            set `axis=1` in `BatchNormalization`.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "            When the next layer is linear (also e.g. `nn.relu`),\n",
        "            this can be disabled since the scaling\n",
        "            will be done by the next layer.\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "    # Input shape\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "    # Output shape\n",
        "        Same shape as input.\n",
        "    # References\n",
        "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 groups=32,\n",
        "                 axis=-1,\n",
        "                 epsilon=1e-5,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 beta_initializer='zeros',\n",
        "                 gamma_initializer='ones',\n",
        "                 beta_regularizer=None,\n",
        "                 gamma_regularizer=None,\n",
        "                 beta_constraint=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(GroupNormalization, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.groups = groups\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "\n",
        "        if dim is None:\n",
        "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
        "                             'input tensor should have a defined dimension '\n",
        "                             'but the layer received an input with shape ' +\n",
        "                             str(input_shape) + '.')\n",
        "\n",
        "        if dim < self.groups:\n",
        "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
        "                             'more than the number of channels (' +\n",
        "                             str(dim) + ').')\n",
        "\n",
        "        if dim % self.groups != 0:\n",
        "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
        "                             'multiple of the number of channels (' +\n",
        "                             str(dim) + ').')\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
        "                                    axes={self.axis: dim})\n",
        "        shape = (dim,)\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(shape=shape,\n",
        "                                         name='gamma',\n",
        "                                         initializer=self.gamma_initializer,\n",
        "                                         regularizer=self.gamma_regularizer,\n",
        "                                         constraint=self.gamma_constraint)\n",
        "        else:\n",
        "            self.gamma = None\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=shape,\n",
        "                                        name='beta',\n",
        "                                        initializer=self.beta_initializer,\n",
        "                                        regularizer=self.beta_regularizer,\n",
        "                                        constraint=self.beta_constraint)\n",
        "        else:\n",
        "            self.beta = None\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        tensor_input_shape = K.shape(inputs)\n",
        "\n",
        "        # Prepare broadcasting shape.\n",
        "        reduction_axes = list(range(len(input_shape)))\n",
        "        del reduction_axes[self.axis]\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
        "        broadcast_shape.insert(1, self.groups)\n",
        "\n",
        "        reshape_group_shape = K.shape(inputs)\n",
        "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
        "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
        "        group_axes.insert(1, self.groups)\n",
        "\n",
        "        # reshape inputs to new group shape\n",
        "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
        "        group_shape = K.stack(group_shape)\n",
        "        inputs = K.reshape(inputs, group_shape)\n",
        "\n",
        "        group_reduction_axes = list(range(len(group_axes)))\n",
        "        group_reduction_axes = group_reduction_axes[2:]\n",
        "\n",
        "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
        "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
        "\n",
        "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
        "\n",
        "        # prepare broadcast shape\n",
        "        inputs = K.reshape(inputs, group_shape)\n",
        "        outputs = inputs\n",
        "\n",
        "        # In this case we must explicitly broadcast all parameters.\n",
        "        if self.scale:\n",
        "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "            outputs = outputs * broadcast_gamma\n",
        "\n",
        "        if self.center:\n",
        "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "            outputs = outputs + broadcast_beta\n",
        "\n",
        "        outputs = K.reshape(outputs, tensor_input_shape)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'groups': self.groups,\n",
        "            'axis': self.axis,\n",
        "            'epsilon': self.epsilon,\n",
        "            'center': self.center,\n",
        "            'scale': self.scale,\n",
        "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
        "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
        "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
        "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
        "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
        "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
        "        }\n",
        "        base_config = super(GroupNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "get_custom_objects().update({'GroupNormalization': GroupNormalization})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from keras.layers import Input\n",
        "    from keras.models import Model\n",
        "    ip = Input(shape=(None, None, 4))\n",
        "    #ip = Input(batch_shape=(100, None, None, 2))\n",
        "    x = GroupNormalization(groups=2, axis=-1, epsilon=0.1)(ip)\n",
        "    model = Model(ip, x)\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 4)     0         \n",
            "_________________________________________________________________\n",
            "group_normalization_1 (Group (None, None, None, 4)     8         \n",
            "=================================================================\n",
            "Total params: 8\n",
            "Trainable params: 8\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbmZ9QOImf3a"
      },
      "source": [
        "### Efficient Net\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIDnpSD7dhwm",
        "outputId": "c0d3b930-48ef-4f1a-f63b-9a438cb3d79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install efficientnet\n",
        "import efficientnet.keras as efn "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGO1n1txvBJ1"
      },
      "source": [
        "class FixedImageDataGenerator(ImageDataGenerator):\n",
        "  def standardize(self, x):\n",
        "    if self.featurewise_center:\n",
        "      img = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "      # x = ((x/255.) - 0.5) * 2.\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZcj06j9Aa8q"
      },
      "source": [
        "IMG_WIDTH = 227\n",
        "IMG_HEIGHT = 227\n",
        "CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpFhFfGsVk7j",
        "outputId": "9214f3b7-818a-4d0d-8d2d-9ed7560502c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_gen_args = dict(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train_datagen = FixedImageDataGenerator(**data_gen_args)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/train',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "data_gen_args = dict(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        ")\n",
        "validate_datagen = FixedImageDataGenerator(**data_gen_args)\n",
        "validate_generator = validate_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/test',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14047 images belonging to 2 classes.\n",
            "Found 3445 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWQvUMCIdugr"
      },
      "source": [
        "def efficientnetB0():\n",
        "    model_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
        "    baseModel = efn.EfficientNetB0(weights='imagenet', include_top=False, input_tensor=model_input)\n",
        "    # for layer in baseModel.layers:\n",
        "\t#     layer.trainable = False\n",
        "    for i, layer in enumerate(baseModel.layers):\n",
        "        if \"batch_normalization\" in layer.name:\n",
        "            baseModel.layers[i] = GroupNormalization(groups=32, axis=-1, epsilon=0.00001)\n",
        "    X = baseModel.output\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "    X = Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.1, l2=0.1))(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(2, activation=\"softmax\")(X)\n",
        "    model = Model(inputs=model_input, outputs=X)\n",
        "    model.compile(optimizer=Adam(lr=1e-3, beta_1=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqOK2WUydujP",
        "outputId": "cd150ea9-bcaf-4a17-b3e1-2c16b231d062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "efficientnetb0_model = efficientnetB0()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16809984/16804768 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzEA43qPrLLC"
      },
      "source": [
        "filepath= \"effinet-gender-b2-v4.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                        factor=0.5, \n",
        "                        patience=2, \n",
        "                        verbose=1, \n",
        "                        mode='auto', \n",
        "                        min_delta=0.0001)\n",
        "callbacks_list = [checkpoint, early, rlr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRX_IIMrLOY",
        "outputId": "6e187361-093c-4c25-d217-089648f77c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = efficientnetb0_model.fit_generator(train_generator, \n",
        "                              steps_per_epoch = train_generator.samples // batch_size, \n",
        "                              epochs = epochs,\n",
        "                              validation_data = validate_generator,\n",
        "                              validation_steps= validate_generator.samples // batch_size, \n",
        "                              callbacks = callbacks_list,\n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "438/438 [==============================] - 289s 660ms/step - loss: 0.7423 - accuracy: 0.9924 - val_loss: 0.8330 - val_accuracy: 0.9270\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.93818\n",
            "Epoch 2/10\n",
            "438/438 [==============================] - 291s 665ms/step - loss: 0.7467 - accuracy: 0.9935 - val_loss: 1.1699 - val_accuracy: 0.9241\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.93818\n",
            "Epoch 3/10\n",
            "438/438 [==============================] - 291s 664ms/step - loss: 0.7528 - accuracy: 0.9923 - val_loss: 0.8387 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.93818\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 4/10\n",
            "438/438 [==============================] - 290s 663ms/step - loss: 0.4745 - accuracy: 0.9935 - val_loss: 0.6917 - val_accuracy: 0.9317\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.93818\n",
            "Epoch 5/10\n",
            "438/438 [==============================] - 290s 662ms/step - loss: 0.4758 - accuracy: 0.9941 - val_loss: 0.5569 - val_accuracy: 0.9326\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.93818\n",
            "Epoch 6/10\n",
            "438/438 [==============================] - 290s 661ms/step - loss: 0.4809 - accuracy: 0.9938 - val_loss: 0.5203 - val_accuracy: 0.9279\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.93818\n",
            "Epoch 7/10\n",
            "438/438 [==============================] - 289s 661ms/step - loss: 0.4678 - accuracy: 0.9947 - val_loss: 0.5836 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.93818\n",
            "Epoch 8/10\n",
            "438/438 [==============================] - 288s 658ms/step - loss: 0.4727 - accuracy: 0.9946 - val_loss: 0.6466 - val_accuracy: 0.9291\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.93818\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 9/10\n",
            "438/438 [==============================] - 288s 657ms/step - loss: 0.3589 - accuracy: 0.9949 - val_loss: 0.4634 - val_accuracy: 0.9326\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.93818\n",
            "Epoch 10/10\n",
            "438/438 [==============================] - 287s 656ms/step - loss: 0.3515 - accuracy: 0.9949 - val_loss: 0.3460 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.93818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUBBAmBQrLWJ"
      },
      "source": [
        "!cp  '/content/effinet-gender-b2-v4-938.hdf5' '/content/drive/My Drive/Adience'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rX6sogCBOge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}