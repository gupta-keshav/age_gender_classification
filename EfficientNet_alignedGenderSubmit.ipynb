{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet alignedGenderSubmit.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta-keshav/age_gender_classification/blob/master/EfficientNet_alignedGenderSubmit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi2bD-3JgRSj",
        "outputId": "5f890bd6-c19d-40bc-ab38-6baa026a6637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHHU8MhgZaT",
        "outputId": "4532418f-59d2-4bce-d88d-dee45e2de4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "%pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/My Drive/Adience/alignedGender.rar\", outdir=\"/content\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting /content/drive/My Drive/Adience/alignedGender.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/drive/My Drive/Adience/alignedGender.rar\"\n",
            "patool:     with cwd='/content'\n",
            "patool: ... /content/drive/My Drive/Adience/alignedGender.rar extracted to `/content'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-4IismlglgK",
        "outputId": "df9d1218-5819-42d0-d93e-1d0dee4f9d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras\n",
        "import  tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, PReLU, ReLU, Input, GlobalAveragePooling2D\n",
        "from keras import optimizers, regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "np.random.seed(48)\n",
        "from keras.applications import vgg19\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "# input_shape = (224, 224, 3)\n",
        "# vgg = vgg19.VGG19(include_top=False ,weights='imagenet', \n",
        "#                                      input_shape=input_shape)   \n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIDnpSD7dhwm",
        "outputId": "e0c17938-fe5b-443c-ab38-af1571615d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "!pip install efficientnet\n",
        "import efficientnet.keras as efn "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGO1n1txvBJ1"
      },
      "source": [
        "from efficientnet.keras import preprocess_input\n",
        "class FixedImageDataGenerator(ImageDataGenerator):\n",
        "  def standardize(self, x):\n",
        "    if self.featurewise_center:\n",
        "      img = preprocess_input(x)\n",
        "      # x = ((x/255.) - 0.5) * 2.\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZcj06j9Aa8q"
      },
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpFhFfGsVk7j",
        "outputId": "8b6a4503-5838-42a9-ebaf-c9bf24cddcab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_gen_args = dict(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train_datagen = FixedImageDataGenerator(**data_gen_args)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/train',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "data_gen_args = dict(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        ")\n",
        "validate_datagen = FixedImageDataGenerator(**data_gen_args)\n",
        "validate_generator = validate_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/test',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14047 images belonging to 2 classes.\n",
            "Found 3445 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWQvUMCIdugr"
      },
      "source": [
        "def efficientnetB0(model_input):\n",
        "    baseModel = efn.EfficientNetB0(weights='imagenet', include_top=False, input_tensor=model_input)\n",
        "    # for layer in baseModel.layers:\n",
        "\t#     layer.trainable = False\n",
        "    # for i, layer in enumerate(baseModel.layers):\n",
        "    #     if \"batch_normalization\" in layer.name:\n",
        "    #         baseModel.layers[i] = GroupNormalization(groups=32, axis=-1, epsilon=0.00001)\n",
        "    X = baseModel.output\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "    X = Dense(4096, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.1, l2=0.1))(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(2, activation=\"softmax\")(X)\n",
        "    model = Model(inputs=model_input, outputs=X)\n",
        "    model.compile(optimizer=Adam(lr=1e-3, beta_1=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqOK2WUydujP",
        "outputId": "1b836db2-e11d-44a3-bb4d-961707770781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
        "efficientnetb0_model = efficientnetB0(model_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16809984/16804768 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlwpVOGjMVW"
      },
      "source": [
        "# efficientnetb0_model = load_model('/content/drive/My Drive/Adience/efficientnet.hdf5')\n",
        "# efficientnetb0_model.load_weights('/content/drive/My Drive/Adience/effinet-adience-91.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzEA43qPrLLC"
      },
      "source": [
        "filepath= \"effinet-gender-v2.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                        factor=0.5, \n",
        "                        patience=2, \n",
        "                        verbose=1, \n",
        "                        mode='auto', \n",
        "                        min_delta=0.0001)\n",
        "callbacks_list = [checkpoint, early, rlr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRX_IIMrLOY",
        "outputId": "c6ec2333-8793-46f2-95b8-16e14ee8cc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = efficientnetb0_model.fit_generator(train_generator, \n",
        "                              steps_per_epoch = train_generator.samples // batch_size, \n",
        "                              epochs = epochs,\n",
        "                              validation_data = validate_generator,\n",
        "                              validation_steps= validate_generator.samples // batch_size, \n",
        "                              callbacks = callbacks_list,\n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "438/438 [==============================] - 441s 1s/step - loss: 345.9186 - accuracy: 0.8454 - val_loss: 65.3416 - val_accuracy: 0.7979\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79790, saving model to effinet-gender-v2.hdf5\n",
            "Epoch 2/10\n",
            "438/438 [==============================] - 412s 940ms/step - loss: 63.5230 - accuracy: 0.8690 - val_loss: 62.7724 - val_accuracy: 0.8687\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.79790 to 0.86874, saving model to effinet-gender-v2.hdf5\n",
            "Epoch 3/10\n",
            "438/438 [==============================] - 410s 936ms/step - loss: 62.3212 - accuracy: 0.8818 - val_loss: 61.5368 - val_accuracy: 0.8579\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.86874\n",
            "Epoch 4/10\n",
            "438/438 [==============================] - 405s 925ms/step - loss: 61.7689 - accuracy: 0.8951 - val_loss: 60.1763 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.86874 to 0.89540, saving model to effinet-gender-v2.hdf5\n",
            "Epoch 5/10\n",
            "438/438 [==============================] - 398s 908ms/step - loss: 61.0353 - accuracy: 0.9149 - val_loss: 60.5969 - val_accuracy: 0.8509\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89540\n",
            "Epoch 6/10\n",
            "438/438 [==============================] - 394s 900ms/step - loss: 60.4632 - accuracy: 0.9188 - val_loss: 59.4053 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89540\n",
            "Epoch 7/10\n",
            "438/438 [==============================] - 393s 898ms/step - loss: 59.8778 - accuracy: 0.9191 - val_loss: 58.5478 - val_accuracy: 0.9121\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.89540 to 0.91210, saving model to effinet-gender-v2.hdf5\n",
            "Epoch 8/10\n",
            "438/438 [==============================] - 394s 900ms/step - loss: 59.1428 - accuracy: 0.9363 - val_loss: 58.5843 - val_accuracy: 0.9004\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91210\n",
            "Epoch 9/10\n",
            "438/438 [==============================] - 393s 898ms/step - loss: 59.3216 - accuracy: 0.9197 - val_loss: 58.6766 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91210\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 10/10\n",
            "438/438 [==============================] - 393s 896ms/step - loss: 30.9976 - accuracy: 0.9625 - val_loss: 29.6069 - val_accuracy: 0.9162\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.91210 to 0.91620, saving model to effinet-gender-v2.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUBBAmBQrLWJ"
      },
      "source": [
        "!cp  '/content/effinet-gender-v2-928.hdf5' '/content/drive/My Drive/Adience'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rX6sogCBOge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vS8H-idBOlz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO8LOy7LBOja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VKsjiXhhH6r",
        "outputId": "ae11cef8-698d-4486-aadf-2e6601c4608c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last = vgg.output\n",
        "print(vgg.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"block5_pool/MaxPool:0\", shape=(?, 7, 7, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm8zCVROhUlL",
        "outputId": "fe284ea2-70d2-4487-b977-f22653ae893c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "x = Flatten()(last)\n",
        "# x = keras.layers.BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(4096, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.1, l2=0.1))(x)\n",
        "# x = keras.layers.BatchNormalization()(x)\n",
        "x = Dropout(0.55)(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok65GqWjhWvq"
      },
      "source": [
        "preds = Dense(1, activation = 'sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-poRjNdhYRk"
      },
      "source": [
        "model = Model(vgg.input, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nif4bgjZhZyK"
      },
      "source": [
        "import pandas as pd\n",
        "layers = [(layer.output, layer.name, layer.trainable) for layer in model.layers]\n",
        "pd.set_option('max_colwidth', -1)\n",
        "\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE5-aszKhbSC"
      },
      "source": [
        "for i in range(17):\n",
        "  model.layers[i].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2BzXZlXimTO"
      },
      "source": [
        "efficientnetb0_model.compile(optimizer = optimizers.Adam(lr=1e-4), loss= 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb7poJHtPEYU"
      },
      "source": [
        "import tensorflow as tf\n",
        "def preprocess(img):\n",
        "  img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gB74pwhcii",
        "outputId": "80b22e54-97bd-4b29-a89e-dd049e3c18a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "data_gen_args = dict(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train_datagen = FixedImageDataGenerator(**data_gen_args)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "validate_generator = train_datagen.flow_from_directory(\n",
        "        '/content/alignedGender/test',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14047 images belonging to 2 classes.\n",
            "Found 3445 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F25ps4cghits"
      },
      "source": [
        "history = efficientnetb0_model.fit_generator(train_generator, steps_per_epoch=440, epochs=3, verbose=1, callbacks=None, validation_data=validate_generator, validation_steps=110, validation_freq=1, class_weight=None, max_queue_size=10, workers=-1, use_multiprocessing=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG0269CezJDX"
      },
      "source": [
        "history = efficientnetb0_model.fit_generator(train_generator, steps_per_epoch=440, epochs=2, verbose=1, callbacks=None, validation_data=validate_generator, validation_steps=110, validation_freq=1, class_weight=None, max_queue_size=10, workers=-1, use_multiprocessing=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwFCCqcMzMHe"
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=440, epochs=1, verbose=1, callbacks=None, validation_data=validate_generator, validation_steps=110, validation_freq=1, class_weight=None, max_queue_size=10, workers=-1, use_multiprocessing=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_t2UA5TVwSV"
      },
      "source": [
        "history = efficientnetb0_model.fit_generator(train_generator, steps_per_epoch=440, epochs=3, verbose=1, callbacks=None, validation_data=validate_generator, validation_steps=110, validation_freq=1, class_weight=None, max_queue_size=10, workers=-1, use_multiprocessing=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-A_Mo_C-mub"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}